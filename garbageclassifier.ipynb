{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Test', 'Train']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input/dataset/Dataset\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "1da1eb23cec130d130336f0b1da16d1803c3a049"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import vgg16\n",
    "\n",
    "model = vgg16.VGG16(weights = \"imagenet\", include_top=False, input_shape = (224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:3]:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "a00a8b9c9c482170b081e4ac3dc2bdf115449f01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2024 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   zoom_range = 0.5,\n",
    "                                   shear_range=0.5,\n",
    "                                   horizontal_flip=True,\n",
    "\n",
    "#                                   fill_mode = 'nearest'\n",
    "                                  )                                  \n",
    "test_datagen = ImageDataGenerator(rescale = 1./255\n",
    "                                 )\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('../input/dataset/Dataset/Train',\n",
    "                                                target_size = (224, 224),\n",
    "                                               batch_size = 32,\n",
    "                                              #color_mode= \"grayscale\",\n",
    "                                              class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "476901af228be2f3d241ff208ac56b95f5b535d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 503 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "testing_set = test_datagen.flow_from_directory('../input/dataset/Dataset/Test',\n",
    "                                               target_size = (224,224),\n",
    "                                               batch_size = 32,\n",
    "                                               #color_mode = 'grayscale',\n",
    "                                               class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "542551342ca69d4d1c47019b855edcbdad847d39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import GlobalMaxPooling2D,GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Dense, Flatten, Lambda\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(2048, activation=\"relu\")(x)\n",
    "\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(6, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.001,decay=1e-5, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "2e0ae27ded61d2f8ff9d3f71e43a46529d908085"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n",
      "512/512 [==============================] - 270s 528ms/step - loss: 0.8540 - acc: 0.6726 - val_loss: 0.7638 - val_acc: 0.7416\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.74155, saving model to weights-improvement-01-0.74.hdf5\n",
      "Epoch 2/15\n",
      "512/512 [==============================] - 253s 495ms/step - loss: 0.3228 - acc: 0.8884 - val_loss: 0.4880 - val_acc: 0.8310\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.74155 to 0.83101, saving model to weights-improvement-02-0.83.hdf5\n",
      "Epoch 3/15\n",
      "512/512 [==============================] - 254s 497ms/step - loss: 0.1595 - acc: 0.9447 - val_loss: 0.8771 - val_acc: 0.7853\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.83101\n",
      "Epoch 4/15\n",
      "512/512 [==============================] - 254s 496ms/step - loss: 0.1089 - acc: 0.9623 - val_loss: 0.6093 - val_acc: 0.8231\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.83101\n",
      "Epoch 5/15\n",
      "512/512 [==============================] - 253s 495ms/step - loss: 0.0778 - acc: 0.9742 - val_loss: 0.7001 - val_acc: 0.8191\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.83101\n",
      "Epoch 6/15\n",
      "512/512 [==============================] - 253s 495ms/step - loss: 0.0614 - acc: 0.9786 - val_loss: 0.7946 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.83101\n",
      "Epoch 7/15\n",
      "512/512 [==============================] - 255s 498ms/step - loss: 0.0396 - acc: 0.9871 - val_loss: 0.6468 - val_acc: 0.8529\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.83101 to 0.85288, saving model to weights-improvement-07-0.85.hdf5\n",
      "Epoch 8/15\n",
      "512/512 [==============================] - 256s 501ms/step - loss: 0.0311 - acc: 0.9900 - val_loss: 0.6946 - val_acc: 0.8529\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.85288\n",
      "Epoch 9/15\n",
      "512/512 [==============================] - 254s 496ms/step - loss: 0.0148 - acc: 0.9950 - val_loss: 0.7563 - val_acc: 0.8469\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.85288\n",
      "Epoch 10/15\n",
      "512/512 [==============================] - 254s 495ms/step - loss: 0.0193 - acc: 0.9941 - val_loss: 0.8901 - val_acc: 0.8191\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.85288\n",
      "Epoch 11/15\n",
      "512/512 [==============================] - 253s 495ms/step - loss: 0.0219 - acc: 0.9931 - val_loss: 1.0083 - val_acc: 0.7952\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.85288\n",
      "Epoch 12/15\n",
      "512/512 [==============================] - 253s 493ms/step - loss: 0.0226 - acc: 0.9922 - val_loss: 0.6782 - val_acc: 0.8549\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.85288 to 0.85487, saving model to weights-improvement-12-0.85.hdf5\n",
      "Epoch 13/15\n",
      "301/512 [================>.............] - ETA: 1:30 - loss: 0.0164 - acc: 0.9943"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "m=model_final.fit_generator(training_set,\n",
    "                         epochs = 15,\n",
    "                         steps_per_epoch = 512,\n",
    "                         validation_data=testing_set,\n",
    "                         validation_steps=256,\n",
    "                        callbacks=callbacks_list\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "9b2f27ce8feee6951742c261038f15409f201e3f"
   },
   "outputs": [],
   "source": [
    "# # Define model\n",
    "# from keras import models\n",
    "# from keras import layers\n",
    "# from keras import optimizers\n",
    "\n",
    "# epochs = 100\n",
    "\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(256, activation='relu' ))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "# model.add(layers.Dense(6, activation='softmax'))\n",
    "# model.summary()\n",
    "# classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "54332bd780d77b15b2c20d6b72dbb6baba5be22c"
   },
   "outputs": [],
   "source": [
    "# classifier.fit_generator(training_set,\n",
    "#                          epochs = 18,\n",
    "#                          steps_per_epoch = 100,\n",
    "#                          verbose = 1,\n",
    "#                          validation_data = testing_set,\n",
    "#                          validation_steps = 64\n",
    "#                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "4e9fbf0e9e3548da90745e4346e0bffe50acc73b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "074bdde708f5b04adbcf45db5ffb445dfb4bebba"
   },
   "outputs": [],
   "source": [
    "# classifier = Sequential()\n",
    "\n",
    "# classifier.add(Conv2D(32, (3, 3), input_shape = (128, 128, 3), activation = 'relu',padding='same'))\n",
    "# classifier.add(MaxPooling2D(pool_size = (3,3)))\n",
    "\n",
    "\n",
    "# classifier.add(Conv2D(64, (3, 3), activation = 'relu',padding='same'))\n",
    "# classifier.add(MaxPooling2D(pool_size = (3,3)))\n",
    "\n",
    "\n",
    "# classifier.add(Conv2D(128, (3, 3), activation = 'relu',padding='same'))\n",
    "# classifier.add(MaxPooling2D(pool_size = (3,3)))\n",
    "\n",
    "# classifier.add(Conv2D(128, (3, 3), activation = 'relu',padding='same'))\n",
    "# classifier.add(MaxPooling2D(pool_size = (3,3)))\n",
    "\n",
    "# classifier.add(Conv2D(64, (3, 3), activation = 'relu',padding='same'))\n",
    "# classifier.add(MaxPooling2D(pool_size = (3,3)))\n",
    "\n",
    "# classifier.add(Conv2D(32, (3, 3), activation = 'relu',padding='same'))\n",
    "# classifier.add(MaxPooling2D(pool_size = (3,3)))\n",
    "\n",
    "# classifier.add(Flatten())\n",
    "# classifier.add(Dense(2048, activation = 'relu'))\n",
    "# classifier.add(BatchNormalization())\n",
    "# classifier.add(Dropout(0.5))\n",
    "# classifier.add(Dense(6, activation = 'softmax'))\n",
    "\n",
    "# classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "62860b51067bd6e86446f5324394916253de791f",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "32b1fdecb92ee747e8d336d1eff225197d2d7302"
   },
   "outputs": [],
   "source": [
    "# classifier.fit_generator(training_set,\n",
    "#                          epochs = 18,\n",
    "#                          steps_per_epoch = 100,\n",
    "#                          verbose = 1,\n",
    "#                          validation_data = testing_set,\n",
    "#                          validation_steps = 64\n",
    "#                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "b3b2fededc2dbabb7e3283ad3695ccf433690274"
   },
   "outputs": [],
   "source": [
    "# # import pickle\n",
    "\n",
    "# filename = 'finalized_model.h5'\n",
    "# # pickle.dump(model, open(filename, 'wb'))\n",
    "# classifier.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "7cdd38097d2d4eb444026bc0260187d6227e4408"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "18d2fce281a55f9c5a9a0d6096ef8db677f75843"
   },
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import load_img\n",
    "# from keras.preprocessing.image import img_to_array\n",
    "# from keras.applications.vgg16 import preprocess_input\n",
    "# from keras.applications.vgg16 import decode_predictions\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# # load the model\n",
    "# model = VGG16()\n",
    "# # load an image from file\n",
    "# image = load_img('mug.jpg', target_size=(224, 224))\n",
    "# # convert the image pixels to a numpy array\n",
    "# image = img_to_array(image)\n",
    "# # reshape data for the model\n",
    "# image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "# # prepare the image for the VGG model\n",
    "# image = preprocess_input(image)\n",
    "# # predict the probability across all output classes\n",
    "# yhat = model.predict(image)\n",
    "# # convert the probabilities to class labels\n",
    "# label = decode_predictions(yhat)\n",
    "# # retrieve the most likely result, e.g. highest probability\n",
    "# label = label[0][0]\n",
    "# # print the classification\n",
    "# print('%s (%.2f%%)' % (label[1], label[2]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
